{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "name_list = [\"aclue\",\"arc_c\",\"cmmlu\",\"hotpot_qa\",\"math\",\"mmlu\",\"squad\"]\n",
    "model_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========aclue==========\n",
      "qwen25_72b_instruct: 0.6575\n",
      "gpt_4o_mini_cot: 0.519375\n",
      "ministral_8b_instruct_2410: 0.30375\n",
      "deepseek_chat: 0.67\n",
      "glm_4_plus: 0.681875\n",
      "llama31_8b_instruct: 0.34375\n",
      "qwen25_32b_int4: 0.65875\n",
      "gpt_4o: 0.623125\n",
      "glm_4_air: 0.58875\n",
      "gpt_4o_mini: 0.52\n",
      "qwen25_math_7b_instruct: 0.021875\n",
      "llama31_70b_instruct: 0.506875\n",
      "mistral_7b_instruct_v02: 0.136875\n",
      "mixtral_8x7b_instruct: 0.1875\n",
      "glm_4_flash: 0.545\n",
      "qwq_32b_preview: 0.47125\n",
      "gemini15_flash: 0.565625\n",
      "deepseek_coder: 0.670625\n",
      "qwen25_7b_instruct: 0.529375\n",
      "llama31_405b_instruct: 0.59375\n",
      "=========arc_c==========\n",
      "qwen25_72b_instruct: 0.9568480300187617\n",
      "gpt_4o_mini_cot: 0.9387116948092558\n",
      "ministral_8b_instruct_2410: 0.7460913070669168\n",
      "deepseek_chat: 0.9549718574108818\n",
      "glm_4_plus: 0.9706066291432145\n",
      "llama31_8b_instruct: 0.22326454033771106\n",
      "qwen25_32b_int4: 0.959349593495935\n",
      "gpt_4o: 0.9662288930581614\n",
      "glm_4_air: 0.9499687304565353\n",
      "gpt_4o_mini: 0.9349593495934959\n",
      "qwen25_math_7b_instruct: 0.03377110694183865\n",
      "llama31_70b_instruct: 0.9362101313320825\n",
      "mistral_7b_instruct_v02: 0.011882426516572859\n",
      "mixtral_8x7b_instruct: 0.46841776110068795\n",
      "glm_4_flash: 0.8424015009380863\n",
      "qwq_32b_preview: 0.8761726078799249\n",
      "gemini15_flash: 0.9487179487179487\n",
      "deepseek_coder: 0.9487179487179487\n",
      "qwen25_7b_instruct: 0.858036272670419\n",
      "llama31_405b_instruct: 0.9505941213258287\n",
      "=========cmmlu==========\n",
      "qwen25_72b_instruct: 0.85425\n",
      "gpt_4o_mini_cot: 0.656625\n",
      "ministral_8b_instruct_2410: 0.43475\n",
      "deepseek_chat: 0.82225\n",
      "glm_4_plus: 0.841375\n",
      "llama31_8b_instruct: 0.479125\n",
      "qwen25_32b_int4: 0.829875\n",
      "gpt_4o: 0.787375\n",
      "glm_4_air: 0.766375\n",
      "gpt_4o_mini: 0.675125\n",
      "qwen25_math_7b_instruct: 0.033375\n",
      "llama31_70b_instruct: 0.686\n",
      "mistral_7b_instruct_v02: 0.196375\n",
      "mixtral_8x7b_instruct: 0.221\n",
      "glm_4_flash: 0.724875\n",
      "qwq_32b_preview: 0.593875\n",
      "gemini15_flash: 0.722375\n",
      "deepseek_coder: 0.82225\n",
      "qwen25_7b_instruct: 0.695625\n",
      "llama31_405b_instruct: 0.756\n",
      "=========hotpot_qa==========\n",
      "qwen25_72b_instruct: 0.30625\n",
      "gpt_4o_mini_cot: 0.32375\n",
      "ministral_8b_instruct_2410: 0.148125\n",
      "deepseek_chat: 0.371875\n",
      "glm_4_plus: 0.354375\n",
      "llama31_8b_instruct: 0.08\n",
      "qwen25_32b_int4: 0.26625\n",
      "gpt_4o: 0.42875\n",
      "glm_4_air: 0.280625\n",
      "gpt_4o_mini: 0.3275\n",
      "qwen25_math_7b_instruct: 0.01875\n",
      "llama31_70b_instruct: 0.311875\n",
      "mistral_7b_instruct_v02: 0.029375\n",
      "mixtral_8x7b_instruct: 0.11375\n",
      "glm_4_flash: 0.1975\n",
      "qwq_32b_preview: 0.04875\n",
      "gemini15_flash: 0.266875\n",
      "deepseek_coder: 0.3775\n",
      "qwen25_7b_instruct: 0.198125\n",
      "llama31_405b_instruct: 0.37375\n",
      "moonshot_v1_search: 0.0\n",
      "=========math==========\n",
      "qwen25_72b_instruct: 0.768125\n",
      "gpt_4o_mini_cot: 0.690625\n",
      "ministral_8b_instruct_2410: 0.4775\n",
      "deepseek_chat: 0.82375\n",
      "glm_4_plus: 0.70625\n",
      "llama31_8b_instruct: 0.384375\n",
      "qwen25_32b_int4: 0.778125\n",
      "gpt_4o: 0.7475\n",
      "glm_4_air: 0.461875\n",
      "gpt_4o_mini: 0.71375\n",
      "qwen25_math_7b_instruct: 0.753125\n",
      "llama31_70b_instruct: 0.470625\n",
      "mistral_7b_instruct_v02: 0.07625\n",
      "mixtral_8x7b_instruct: 0.156875\n",
      "glm_4_flash: 0.155625\n",
      "qwq_32b_preview: 0.808125\n",
      "gemini15_flash: 0.75\n",
      "deepseek_coder: 0.8275\n",
      "qwen25_7b_instruct: 0.255\n",
      "llama31_405b_instruct: 0.651875\n",
      "=========mmlu==========\n",
      "qwen25_72b_instruct: 0.8174340634778722\n",
      "gpt_4o_mini_cot: 0.7724631202503353\n",
      "ministral_8b_instruct_2410: 0.5367009387572642\n",
      "deepseek_chat: 0.8413053196244971\n",
      "glm_4_plus: 0.812784979883773\n",
      "llama31_8b_instruct: 0.21957979436745642\n",
      "qwen25_32b_int4: 0.8015198927134555\n",
      "gpt_4o: 0.8396960214573089\n",
      "glm_4_air: 0.772820742065266\n",
      "gpt_4o_mini: 0.7546714349575324\n",
      "qwen25_math_7b_instruct: 0.04255699597675458\n",
      "llama31_70b_instruct: 0.7983907018328118\n",
      "mistral_7b_instruct_v02: 0.013500223513634332\n",
      "mixtral_8x7b_instruct: 0.48368350469378635\n",
      "glm_4_flash: 0.40813589628967367\n",
      "qwq_32b_preview: 0.6470272686633884\n",
      "gemini15_flash: 0.7766651765757712\n",
      "deepseek_coder: 0.8418417523468932\n",
      "qwen25_7b_instruct: 0.6300402324541797\n",
      "llama31_405b_instruct: 0.8506034868126956\n",
      "=========squad==========\n",
      "qwen25_72b_instruct: 0.8117897570944299\n",
      "gpt_4o_mini_cot: 0.8343771950621997\n",
      "ministral_8b_instruct_2410: 0.5924762404200561\n",
      "deepseek_chat: 0.8042910622767491\n",
      "glm_4_plus: 0.7718407325615034\n",
      "llama31_8b_instruct: 0.4727606629309789\n",
      "qwen25_32b_int4: 0.8370442817478795\n",
      "gpt_4o: 0.5450624068009069\n",
      "glm_4_air: 0.7261312491836006\n",
      "gpt_4o_mini: 0.7020875661254238\n",
      "qwen25_math_7b_instruct: 0.2233318182078439\n",
      "llama31_70b_instruct: 0.7537829490785366\n",
      "mistral_7b_instruct_v02: 0.3416747849216572\n",
      "mixtral_8x7b_instruct: 0.3192884122608708\n",
      "glm_4_flash: 0.7566852703758344\n",
      "qwq_32b_preview: 0.4069368577505348\n",
      "gemini15_flash: 0.8229674963486968\n",
      "deepseek_coder: 0.8058757845574243\n",
      "qwen25_7b_instruct: 0.6783525493890972\n",
      "llama31_405b_instruct: 0.8658703773595294\n"
     ]
    }
   ],
   "source": [
    "model_feature = {}\n",
    "for name in name_list:\n",
    "    print(f\"========={name}==========\")\n",
    "    reward_ratios = {}\n",
    "    path = f\"../Demo/data/competition_data/{name}_train.csv\"\n",
    "    dataset = pd.read_csv(path)\n",
    "    models = dataset.columns[2:].tolist()\n",
    "    for model in models:\n",
    "        reward_ratio = dataset[model].sum() / len(dataset)\n",
    "        reward_ratios[model] = reward_ratio\n",
    "        print(f\"{model}: {reward_ratio}\")\n",
    "    model_feature[name] = reward_ratios\n",
    "model_features.append(model_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../Demo/data/model_features.json\"\n",
    "json.dump(model_features, open(output_path, 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
