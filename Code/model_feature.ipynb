{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "name_list = [\"aclue\",\"arc_c\",\"cmmlu\",\"hotpot_qa\",\"math\",\"mmlu\",\"squad\"]\n",
    "model_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========aclue==========\n",
      "qwen25_72b_instruct: 0.6575\n",
      "gpt_4o_mini_cot: 0.519375\n",
      "ministral_8b_instruct_2410: 0.30375\n",
      "deepseek_chat: 0.67\n",
      "glm_4_plus: 0.681875\n",
      "llama31_8b_instruct: 0.34375\n",
      "qwen25_32b_int4: 0.65875\n",
      "gpt_4o: 0.623125\n",
      "glm_4_air: 0.58875\n",
      "gpt_4o_mini: 0.52\n",
      "qwen25_math_7b_instruct: 0.021875\n",
      "llama31_70b_instruct: 0.506875\n",
      "mistral_7b_instruct_v02: 0.136875\n",
      "mixtral_8x7b_instruct: 0.1875\n",
      "glm_4_flash: 0.545\n",
      "qwq_32b_preview: 0.47125\n",
      "gemini15_flash: 0.565625\n",
      "deepseek_coder: 0.670625\n",
      "qwen25_7b_instruct: 0.529375\n",
      "llama31_405b_instruct: 0.59375\n",
      "=========arc_c==========\n",
      "qwen25_72b_instruct: 0.9568480300187617\n",
      "gpt_4o_mini_cot: 0.9387116948092558\n",
      "ministral_8b_instruct_2410: 0.7460913070669168\n",
      "deepseek_chat: 0.9549718574108818\n",
      "glm_4_plus: 0.9706066291432145\n",
      "llama31_8b_instruct: 0.22326454033771106\n",
      "qwen25_32b_int4: 0.959349593495935\n",
      "gpt_4o: 0.9662288930581614\n",
      "glm_4_air: 0.9499687304565353\n",
      "gpt_4o_mini: 0.9349593495934959\n",
      "qwen25_math_7b_instruct: 0.03377110694183865\n",
      "llama31_70b_instruct: 0.9362101313320825\n",
      "mistral_7b_instruct_v02: 0.011882426516572859\n",
      "mixtral_8x7b_instruct: 0.46841776110068795\n",
      "glm_4_flash: 0.8424015009380863\n",
      "qwq_32b_preview: 0.8761726078799249\n",
      "gemini15_flash: 0.9487179487179487\n",
      "deepseek_coder: 0.9487179487179487\n",
      "qwen25_7b_instruct: 0.858036272670419\n",
      "llama31_405b_instruct: 0.9505941213258287\n",
      "=========cmmlu==========\n",
      "qwen25_72b_instruct: 0.85425\n",
      "gpt_4o_mini_cot: 0.656625\n",
      "ministral_8b_instruct_2410: 0.43475\n",
      "deepseek_chat: 0.82225\n",
      "glm_4_plus: 0.841375\n",
      "llama31_8b_instruct: 0.479125\n",
      "qwen25_32b_int4: 0.829875\n",
      "gpt_4o: 0.787375\n",
      "glm_4_air: 0.766375\n",
      "gpt_4o_mini: 0.675125\n",
      "qwen25_math_7b_instruct: 0.033375\n",
      "llama31_70b_instruct: 0.686\n",
      "mistral_7b_instruct_v02: 0.196375\n",
      "mixtral_8x7b_instruct: 0.221\n",
      "glm_4_flash: 0.724875\n",
      "qwq_32b_preview: 0.593875\n",
      "gemini15_flash: 0.722375\n",
      "deepseek_coder: 0.82225\n",
      "qwen25_7b_instruct: 0.695625\n",
      "llama31_405b_instruct: 0.756\n",
      "=========hotpot_qa==========\n",
      "qwen25_72b_instruct: 0.30625\n",
      "gpt_4o_mini_cot: 0.32375\n",
      "ministral_8b_instruct_2410: 0.148125\n",
      "deepseek_chat: 0.371875\n",
      "glm_4_plus: 0.354375\n",
      "llama31_8b_instruct: 0.08\n",
      "qwen25_32b_int4: 0.26625\n",
      "gpt_4o: 0.42875\n",
      "glm_4_air: 0.280625\n",
      "gpt_4o_mini: 0.3275\n",
      "qwen25_math_7b_instruct: 0.01875\n",
      "llama31_70b_instruct: 0.311875\n",
      "mistral_7b_instruct_v02: 0.029375\n",
      "mixtral_8x7b_instruct: 0.11375\n",
      "glm_4_flash: 0.1975\n",
      "qwq_32b_preview: 0.04875\n",
      "gemini15_flash: 0.266875\n",
      "deepseek_coder: 0.3775\n",
      "qwen25_7b_instruct: 0.198125\n",
      "llama31_405b_instruct: 0.37375\n",
      "moonshot_v1_search: 0.0\n",
      "=========math==========\n",
      "qwen25_72b_instruct: 0.768125\n",
      "gpt_4o_mini_cot: 0.690625\n",
      "ministral_8b_instruct_2410: 0.4775\n",
      "deepseek_chat: 0.82375\n",
      "glm_4_plus: 0.70625\n",
      "llama31_8b_instruct: 0.384375\n",
      "qwen25_32b_int4: 0.778125\n",
      "gpt_4o: 0.7475\n",
      "glm_4_air: 0.461875\n",
      "gpt_4o_mini: 0.71375\n",
      "qwen25_math_7b_instruct: 0.753125\n",
      "llama31_70b_instruct: 0.470625\n",
      "mistral_7b_instruct_v02: 0.07625\n",
      "mixtral_8x7b_instruct: 0.156875\n",
      "glm_4_flash: 0.155625\n",
      "qwq_32b_preview: 0.808125\n",
      "gemini15_flash: 0.75\n",
      "deepseek_coder: 0.8275\n",
      "qwen25_7b_instruct: 0.255\n",
      "llama31_405b_instruct: 0.651875\n",
      "=========mmlu==========\n",
      "qwen25_72b_instruct: 0.8174340634778722\n",
      "gpt_4o_mini_cot: 0.7724631202503353\n",
      "ministral_8b_instruct_2410: 0.5367009387572642\n",
      "deepseek_chat: 0.8413053196244971\n",
      "glm_4_plus: 0.812784979883773\n",
      "llama31_8b_instruct: 0.21957979436745642\n",
      "qwen25_32b_int4: 0.8015198927134555\n",
      "gpt_4o: 0.8396960214573089\n",
      "glm_4_air: 0.772820742065266\n",
      "gpt_4o_mini: 0.7546714349575324\n",
      "qwen25_math_7b_instruct: 0.04255699597675458\n",
      "llama31_70b_instruct: 0.7983907018328118\n",
      "mistral_7b_instruct_v02: 0.013500223513634332\n",
      "mixtral_8x7b_instruct: 0.48368350469378635\n",
      "glm_4_flash: 0.40813589628967367\n",
      "qwq_32b_preview: 0.6470272686633884\n",
      "gemini15_flash: 0.7766651765757712\n",
      "deepseek_coder: 0.8418417523468932\n",
      "qwen25_7b_instruct: 0.6300402324541797\n",
      "llama31_405b_instruct: 0.8506034868126956\n",
      "=========squad==========\n",
      "qwen25_72b_instruct: 0.8117897570944299\n",
      "gpt_4o_mini_cot: 0.8343771950621997\n",
      "ministral_8b_instruct_2410: 0.5924762404200561\n",
      "deepseek_chat: 0.8042910622767491\n",
      "glm_4_plus: 0.7718407325615034\n",
      "llama31_8b_instruct: 0.4727606629309789\n",
      "qwen25_32b_int4: 0.8370442817478795\n",
      "gpt_4o: 0.5450624068009069\n",
      "glm_4_air: 0.7261312491836006\n",
      "gpt_4o_mini: 0.7020875661254238\n",
      "qwen25_math_7b_instruct: 0.2233318182078439\n",
      "llama31_70b_instruct: 0.7537829490785366\n",
      "mistral_7b_instruct_v02: 0.3416747849216572\n",
      "mixtral_8x7b_instruct: 0.3192884122608708\n",
      "glm_4_flash: 0.7566852703758344\n",
      "qwq_32b_preview: 0.4069368577505348\n",
      "gemini15_flash: 0.8229674963486968\n",
      "deepseek_coder: 0.8058757845574243\n",
      "qwen25_7b_instruct: 0.6783525493890972\n",
      "llama31_405b_instruct: 0.8658703773595294\n"
     ]
    }
   ],
   "source": [
    "model_feature = {}\n",
    "for name in name_list:\n",
    "    print(f\"========={name}==========\")\n",
    "    reward_ratios = {}\n",
    "    path = f\"../Demo/data/competition_data/{name}_train.csv\"\n",
    "    dataset = pd.read_csv(path)\n",
    "    models = dataset.columns[2:].tolist()\n",
    "    for model in models:\n",
    "        reward_ratio = dataset[model].sum() / len(dataset)\n",
    "        reward_ratios[model] = reward_ratio\n",
    "        # print(f\"{model}: {reward_ratio}\")\n",
    "    model_feature[name] = reward_ratios\n",
    "    print(f\"best model: {max(reward_ratios, key=reward_ratios.get)}\")\n",
    "model_features.append(model_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的训练集语言和数据集的语言一致\n",
    "+ **qwen25_72b_instruct**: 中 & 英\n",
    "+ **gpt_4o_mini_cot**: \n",
    "+ **ministral_8b_instruct_2410**: \n",
    "+ **deepseek_chat**: \n",
    "+ **glm_4_plus**: \n",
    "+ **llama31_8b_instruct**: \n",
    "+ **qwen25_32b_int4**: \n",
    "+ **gpt_4o**: \n",
    "+ **glm_4_air**: \n",
    "+ **gpt_4o_mini**: \n",
    "+ **qwen25_math_7b_instruct**: \n",
    "+ **llama31_70b_instruct**: \n",
    "+ **mistral_7b_instruct_v02**: \n",
    "+ **mixtral_8x7b_instruct**: \n",
    "+ **glm_4_flash**: \n",
    "+ **qwq_32b_preview**: \n",
    "+ **gemini15_flash**: \n",
    "+ **deepseek_coder**: \n",
    "+ **qwen25_7b_instruct**: \n",
    "+ **llama31_405b_instruct**: \n",
    "\n",
    "基于您的查询，我将针对列出的模型在解决“下列选项中[]内的‘使’字翻译为‘官职’的是”这类中文古文理解问题的表现进行评分。评分标准如下：\n",
    "评分范围：1 到 5 分，其中：\n",
    "\n",
    "5 分：表现优秀，能准确解析古文上下文，正确识别“使”字含义（如官职），并选择正确选项（本例中正确答案为 A）。\n",
    "\n",
    "4 分：表现良好，多数情况下正确，但偶尔可能出现推理不精确或轻微错误。\n",
    "\n",
    "3 分：表现中等，有时正确有时错误，对古文理解有限，可能依赖表面语义。\n",
    "\n",
    "2 分：表现较差，经常错误，难以处理古文语义或文化背景。\n",
    "\n",
    "1 分：表现很差，几乎无法处理古文，输出混乱或无关。\n",
    "\n",
    "问题分析：该问题涉及中文古文（文言文）理解，要求模型在上下文中判断“使”字是否表示“官职”（如官职名、使节）。选项解析：\n",
    "\n",
    "A. “六军使” 是一个官职名（类似唐代禁军统帅），正确。\n",
    "\n",
    "B. “使人” 表示“派人”，动词使役，错误。\n",
    "\n",
    "C. “使人” 表示“派人”，动词使役，错误。\n",
    "\n",
    "D. “清江使” 出自《庄子》，指“清江的使者”，但更偏向专有名词而非标准官职；在本题中，A 更直接符合“官职”翻译。\n",
    "\n",
    "评分依据：\n",
    "\n",
    "模型在中文古文能力上的表现（基于训练数据、架构和实测反馈）。\n",
    "\n",
    "英文主导模型（如 Mistral、Llama3 系列）在中文古文上较弱，而中文优化模型（如 Qwen、GLM、DeepSeek-Chat）更强。\n",
    "\n",
    "模型规模、特化领域（如代码、数学）会影响表现：大参数模型通常更好，但特化模型（如数学或代码）在古文上可能较差。\n",
    "\n",
    "评分基于综合社区反馈、基准测试（如 C-Eval 古文子集）和类似问题实测。\n",
    "\n",
    "以下是每个模型的评分及简要理由。评分以表格形式呈现，便于比较。\n",
    "\n",
    "模型评分表\n",
    "模型名称                     评分 理由\n",
    "\n",
    "qwen25_72b_instruct 5 通义千问旗舰模型，中文古文理解极强，能准确解析官职含义（如“六军使”），错误率低。\n",
    "gpt_4o_mini_cot 4 GPT-4o 轻量版，支持思维链推理，英文强但中文古文稍弱；能处理上下文，但偶尔可能过度推理导致偏差。\n",
    "ministral_8b_instruct_2410 2 应为 Mistral 8B 变体，英文主导，中文训练数据不足；古文理解弱，常误判语义（如将“使”视为动词）。\n",
    "deepseek_chat 5 深度求索主力模型，中英文均衡，古文能力优秀；能正确识别官职上下文，表现稳定。\n",
    "glm_4_plus 5 清华 GLM 系列旗舰，中文古文优化明显，对“官职”类术语解析精准，错误极少。\n",
    "llama31_8b_instruct 3 Llama3 8B 小参数版，英文强但中文中等；古文理解有限，可能正确但易受表面语义干扰。\n",
    "qwen25_32b_int4 4 Qwen 32B 量化版，中文能力保持较好；古文解析稍弱于 72B 版，但多数情况正确。\n",
    "gpt_4o 5 GPT-4o 全能模型，中英文顶尖；古文上下文理解强，能高准确率选择正确选项。\n",
    "glm_4_air 4 GLM-4 轻量版，中文优先但能力稍降；古文表现良好，但复杂语境可能出错。\n",
    "gpt_4o_mini 4 GPT-4o 小型版，类似 mini_cot；英文略优，中文古文稍弱，但整体可靠。\n",
    "qwen25_math_7b_instruct 3 数学特化模型，基础中文还行；古文理解一般，可能忽略文化背景（如误判 D 选项）。\n",
    "llama31_70b_instruct 4 Llama3 70B 大参数版，英文强，中文中等；规模提升古文能力，但仍有文化隔阂。\n",
    "mistral_7b_instruct_v02 2 Mistral 7B 英文模型，中文弱；古文处理差，常输出错误解释（如混淆“使”字含义）。\n",
    "mixtral_8x7b_instruct 2 Mixtral 8x7B 英文开源标杆，中文训练不足；古文错误率高，难解析官职语义。\n",
    "glm_4_flash 4 GLM-4 轻量快速版，中文响应快；古文表现较好，但深度解析不如 Plus 版。\n",
    "qwq_32b_preview 4 应为 Qwen 32B 预览版，中文能力好；古文理解可靠，但非旗舰版可能略不稳定。\n",
    "gemini15_flash 4 Gemini 1.5 Flash，英文极强，中文优秀但略逊 GPT-4o；古文表现良好，但偶尔误译。\n",
    "deepseek_coder 2 代码特化模型，英文主导；中文古文弱，常忽略语义（如将“使”视为编程术语）。\n",
    "qwen25_7b_instruct 3 Qwen 7B 基础版，轻量中文；古文能力有限，简单题可能正确，复杂题易错。\n",
    "llama31_405b_instruct 4 Llama3 405B 超大模型，英文顶尖，中文中等；规模提升古文表现，但文化背景理解不如中文优化模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature = {}\n",
    "for name in name_list:\n",
    "    print(f\"========={name}==========\")\n",
    "    reward_ratios = {}\n",
    "    path = f\"../Demo/data/competition_data/{name}_train.csv\"\n",
    "    dataset = pd.read_csv(path)\n",
    "    models = dataset.columns[2:].tolist()\n",
    "    for model in models:\n",
    "        if ()\n",
    "            consistency = 0\n",
    "        else:\n",
    "            consistency = 1\n",
    "        print(f\"{model}: {consistency}\")\n",
    "    model_feature[name] = consistency\n",
    "model_features.append(model_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../Demo/data/model_features.json\"\n",
    "json.dump(model_features, open(output_path, 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
